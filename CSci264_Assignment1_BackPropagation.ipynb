{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nawazkhan7783/CSCi-264/blob/main/CSci264_Assignment1_BackPropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrVbrlm_2fwS"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import math\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sigmoid Function"
      ],
      "metadata": {
        "id": "0YoKbx_VBRK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1.0/(1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "Eu5pjE6HBYzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# F(Model,X) Function"
      ],
      "metadata": {
        "id": "plFS7yM4GSlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum of product of weights with it respective input - Similar to Linear Regression\n",
        "def F(model_weight, X):\n",
        "  return sum([w*x for w,x in zip(model_weight,X)])"
      ],
      "metadata": {
        "id": "1rV2KWPOGV3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Function"
      ],
      "metadata": {
        "id": "OFYHP_oPIrXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, x):\n",
        "  w1 = model[0]\n",
        "  w2 = model[1]\n",
        "  v1 = model[2]\n",
        "\n",
        "  #Calculate Hidden Layer values\n",
        "  z1 = sigmoid(F(w1, x))\n",
        "  z2 = sigmoid(F(w2,x))\n",
        "  Z = (1, z1,z2)\n",
        "\n",
        "  #Calculate Output value from the Z's values\n",
        "  y = sigmoid(F(v1,Z))\n",
        "  return y"
      ],
      "metadata": {
        "id": "JIJSREPlIx8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classify Function\n"
      ],
      "metadata": {
        "id": "CwBepsjsDtlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns 1 if y>0.5 or returns 0\n",
        "def classifyY(Y):\n",
        "  return [1 if y > 0.5 else 0 for y in Y]"
      ],
      "metadata": {
        "id": "SfO1ad17DzIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing Random Weights Function"
      ],
      "metadata": {
        "id": "Y6S26FVXEE0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns randoms weights\n",
        "def RandomWeights():\n",
        "  w1 = [random.uniform(-1,1) for _ in range(3)]\n",
        "  w2 = [random.uniform(-1,1) for _ in range(3)]\n",
        "  v1 = [random.uniform(-1,1) for _ in range(3)]\n",
        "  return [w1,w2,v1]"
      ],
      "metadata": {
        "id": "_ZuyoEaJEI0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropagation"
      ],
      "metadata": {
        "id": "SS3YgttpEPyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "#Initialize\n",
        "model = RandomWeights()\n",
        "trainingData = [((0,0),0), ((0,1),1), ((1,0),1), ((1,1),0)]\n",
        "trainingData = [((1,x1,x2),r) for ((x1,x2),r)in trainingData] #[((1,0,0),0), ((1,0,1),1), ((1,1,0),1), ((1,1,1),0)]\n",
        "\n",
        "alpha = 0.5 #Learning Rate\n",
        "iterations = 2000 # Number of Iterations\n",
        "epoch = 100\n",
        "display = True # Displays the Squared Error and Predicted value\n",
        "\n",
        "def Backpropagation(model,learningRate, epoch, data, iterations, display):\n",
        "\n",
        "  w1 = model[0]\n",
        "  w2 = model[1]\n",
        "  v1 = model[2]\n",
        "\n",
        "  for i in range(iterations):\n",
        "    np.random.shuffle(data) # Shuffling the data\n",
        "\n",
        "    if (i % epoch) == 0:\n",
        "      testData = [ ( (0,0), 0 ), ( (0,1), 1 ), ( (1,0), 1), ( (1,1), 0 ) ]\n",
        "      X = [(1,x1,x2) for ((x1,x2),r) in testData] #Inputs X0,X1,X2\n",
        "      R = [r for ((x1,x2),r) in testData] #Expected Result From Model\n",
        "      yPred = [predict([w1,w2,v1], x) for x in X] #Predicts the values of Y\n",
        "      squaredError = sum([pow(r - y, 2) for (r,y) in zip(R,yPred)]) #Calculating the Squared Error\n",
        "      if display: print(\"Epoch:\",i, f\"{squaredError=} {yPred=}\")\n",
        "\n",
        "    #Foward Pass Calculations\n",
        "    for (x,r) in data: #1st: x = (1,0,0) r = 0, 2nd: x = (1,0,1) r = 1, etc\n",
        "      z1 = sigmoid(F(w1, x))  #Calculating z1 using the sigmoid of w1\n",
        "      z2 = sigmoid(F(w2, x))  #Calculating z2 using the sigmoid of w2\n",
        "      Z = [1, z1, z2] #Hidden Layer (z0 = 1, z1, z2)\n",
        "      y = sigmoid(F(v1,Z))  #Calculating y(output) value\n",
        "\n",
        "      #Backward Pass calculations and Updates\n",
        "      #Similar Calculations to the Logistic regression, but we are applying the z's values (hidden layer)\n",
        "      deltaV = [learningRate * (r - y) * z for z in Z]\n",
        "      deltaZ1 = [learningRate * (r - y) * v1[1] * z1 * (1 - z1) * xLu for xLu in x]\n",
        "      deltaZ2 = [learningRate * (r - y) * v1[2] * z2 * (1 - z2) * xLu for xLu in x]\n",
        "\n",
        "      #Update edges from input to hidden layer\n",
        "      #Updates edges from hidden layer nodes to the output node\n",
        "      v1 = [v + dv for (v,dv) in zip(v1,deltaV)]  #Updating weights of v1\n",
        "      w1 = [w + dw for (w,dw) in zip(w1,deltaZ1)] #Updating weights of w1\n",
        "      w2 = [w + dw for (w,dw) in zip(w2, deltaZ2)]  #Updating weights of w2\n",
        "\n",
        "  newModel = [w1,w2,v1] #List of final weights [w1,w2,v1]\n",
        "  result = classifyY(yPred) #Classifying the output value to 0 if <0.5 and 1 if >0.5\n",
        "\n",
        "  #Calculate Accuracy\n",
        "  error_rate = sum([math.fabs(r-y) for (r,y) in zip(R,yPred)])/4 *100 #Calculating the Error Rate for Accuracy\n",
        "  accuracy = 100 - error_rate #Calculating Accuracy\n",
        "\n",
        "  #Print Results\n",
        "  print(\"Results:\",result, \"\\tExpected:\",R, \"\\tAccuracy:\",accuracy)\n",
        "  return newModel\n",
        "\n",
        "Final_Weights = Backpropagation(model,alpha,epoch,trainingData, iterations, display)\n",
        "print(f\"{Final_Weights=}\") #Printing the Final Values"
      ],
      "metadata": {
        "id": "7Oy3kVoVWJ55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27768911-266b-4d19-d05d-7c5f8c9c475b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 squaredError=1.2956179046282537 yPred=[0.23066230954673, 0.1972978113230738, 0.2582436616383327, 0.21881392637669614]\n",
            "Epoch: 100 squaredError=0.9969829603448584 yPred=[0.5453305166533418, 0.565241185895555, 0.5186495778716262, 0.5280948140502716]\n",
            "Epoch: 200 squaredError=0.7435113790395291 yPred=[0.38653306870223614, 0.8540537904944129, 0.34265021734121137, 0.3750926992205476]\n",
            "Epoch: 300 squaredError=0.3035414937327132 yPred=[0.23991057003771693, 0.9269418467272065, 0.5503621545991018, 0.19614465667077932]\n",
            "Epoch: 400 squaredError=0.009362332860098223 yPred=[0.04587115671158247, 0.9677968796331181, 0.9305536711675332, 0.037394335030438375]\n",
            "Epoch: 500 squaredError=0.0024367844874718983 yPred=[0.023270967379618163, 0.9811030851266602, 0.9659823199327181, 0.019517956240304654]\n",
            "Epoch: 600 squaredError=0.0010819031838739676 yPred=[0.015523757175881205, 0.9868038234950877, 0.9778043860703154, 0.01319590068747998]\n",
            "Epoch: 700 squaredError=0.0006048949196634985 yPred=[0.011632034850022373, 0.9899176387921752, 0.9836044259957537, 0.009955994699556462]\n",
            "Epoch: 800 squaredError=0.00038466997296960156 yPred=[0.009285096010200337, 0.9918579325362866, 0.987022191958621, 0.007983746044835137]\n",
            "Epoch: 900 squaredError=0.0002657093144958108 yPred=[0.00769231066324094, 0.9931523679857339, 0.9892462326626749, 0.006633558246362035]\n",
            "Epoch: 1000 squaredError=0.00019422911763264844 yPred=[0.006569881554368591, 0.9941050215462941, 0.9908312189514039, 0.005678772500062332]\n",
            "Epoch: 1100 squaredError=0.00014799349086317377 yPred=[0.005738939137129766, 0.9948348671401857, 0.992020099057082, 0.004969975042711625]\n",
            "Epoch: 1200 squaredError=0.00011645891914258956 yPred=[0.005086663156562138, 0.9953992227438534, 0.9929320564323049, 0.004411552950771867]\n",
            "Epoch: 1300 squaredError=9.397935452127277e-05 yPred=[0.0045682002450456805, 0.9958549609320371, 0.9936602256178666, 0.003966965206696854]\n",
            "Epoch: 1400 squaredError=7.740799334906725e-05 yPred=[0.004145185144965304, 0.9962300343907131, 0.9942530637972925, 0.0036035422919441806]\n",
            "Epoch: 1500 squaredError=6.484902059528927e-05 yPred=[0.0037920078867768395, 0.9965419467109252, 0.9947441199641524, 0.00329958925937892]\n",
            "Epoch: 1600 squaredError=5.510481169616944e-05 yPred=[0.003493674392429095, 0.9968063169173667, 0.9951582184143658, 0.0030424645241267463]\n",
            "Epoch: 1700 squaredError=4.739149596850522e-05 yPred=[0.0032399309319412744, 0.997035014329246, 0.9955133194373783, 0.0028236325940128276]\n",
            "Epoch: 1800 squaredError=4.1188173701215276e-05 yPred=[0.0030191446181614765, 0.997232203448754, 0.995819086655309, 0.00263290815087377]\n",
            "Epoch: 1900 squaredError=3.612276897260376e-05 yPred=[0.002826521391069345, 0.9974051419211236, 0.9960862876103951, 0.0024663966997168357]\n",
            "Results: [0, 1, 1, 0] \tExpected: [0, 1, 1, 0] \tAccuracy: 99.70496278601831\n",
            "Final_Weights=[[-3.9666562987480143, -7.553199814455869, 7.434995876641082], [3.369078784920498, -6.796585849495102, 7.108976602434789], [5.997211385010491, 12.993070884386347, -12.58543457875804]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Times with Different Initial Random Weights"
      ],
      "metadata": {
        "id": "WZ61i98N1WT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display = False\n",
        "\n",
        "model = RandomWeights()\n",
        "print(\"\\n\\n 1st:\")\n",
        "Final_Weights = Backpropagation(model,alpha,epoch,trainingData, iterations, display)\n",
        "print(\"Final Weights:\",Final_Weights)\n",
        "\n",
        "model = RandomWeights()\n",
        "print(\"\\n\\n 2nd:\")\n",
        "Final_Weights = Backpropagation(model,alpha,epoch,trainingData, iterations, display)\n",
        "print(\"Final Weights:\",Final_Weights)\n",
        "\n",
        "model = RandomWeights()\n",
        "print(\"\\n\\n 3rd:\")\n",
        "Final_Weights = Backpropagation(model,alpha,epoch,trainingData, iterations, display)\n",
        "print(\"Final Weights:\",Final_Weights)\n",
        "\n",
        "model = RandomWeights()\n",
        "print(\"\\n\\n 4th:\")\n",
        "Final_Weights = Backpropagation(model,alpha,epoch,trainingData, iterations, display)\n",
        "print(\"Final Weights:\",Final_Weights)\n",
        "\n",
        "model = RandomWeights()\n",
        "print(\"\\n\\n 5th:\")\n",
        "Final_Weights = Backpropagation(model,alpha,epoch,trainingData, iterations, display)\n",
        "print(\"Final Weights:\",Final_Weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPjMKg13jeJN",
        "outputId": "e1b741ce-c9ac-44eb-9408-400b77a9f739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " 1st:\n",
            "Results: [0, 1, 1, 0] \tExpected: [0, 1, 1, 0] \tAccuracy: 99.69228806750519\n",
            "Final Weights: [[-9.203754140173203, 5.954617433257799, 5.954699903722727], [2.9607496072688617, -7.165919954228175, -7.166044726612595], [6.4327510928957805, -13.163777362575008, -13.06814594380576]]\n",
            "\n",
            "\n",
            " 2nd:\n",
            "Results: [0, 1, 0, 0] \tExpected: [0, 1, 1, 0] \tAccuracy: 74.87669599790216\n",
            "Final Weights: [[1.4827444861896455, -9.469605153685322, -4.700957732532607], [-3.3221973647755885, -9.681175276979928, 4.987512580041152], [0.061384093612847274, -8.145938218117816, 8.042921891482768]]\n",
            "\n",
            "\n",
            " 3rd:\n",
            "Results: [0, 1, 1, 0] \tExpected: [0, 1, 1, 0] \tAccuracy: 99.69889935319888\n",
            "Final Weights: [[8.749112973731297, -5.860767741157474, -5.865967658372871], [3.2249563851936207, -7.49599074953563, -7.534075876626231], [-6.186835426402104, 13.028720464811697, -13.38834899905844]]\n",
            "\n",
            "\n",
            " 4th:\n",
            "Results: [0, 1, 1, 0] \tExpected: [0, 1, 1, 0] \tAccuracy: 99.66397206834854\n",
            "Final Weights: [[8.63093392627951, -5.786437042392298, -5.786637146037642], [3.2346620617578985, -7.5459820430667515, -7.549217309808036], [-6.09226764108955, 12.841366008134228, -13.185660234303826]]\n",
            "\n",
            "\n",
            " 5th:\n",
            "Results: [0, 1, 1, 1] \tExpected: [0, 1, 1, 0] \tAccuracy: 74.86273240229892\n",
            "Final Weights: [[-3.5124945932856813, 5.174118701139776, -9.594244919543106], [1.4346315993462244, -4.4488197564454355, -9.282694160459036], [0.031440668073968725, 8.036924947679175, -8.011379640156788]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Version Backpropagation"
      ],
      "metadata": {
        "id": "9VN3baFxE5HG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "#Initialize\n",
        "model = RandomWeights()\n",
        "trainingData = [((0,0),0), ((0,1),1), ((1,0),1), ((1,1),0)]\n",
        "trainingData = [((1,x1,x2),r) for ((x1,x2),r)in trainingData] #[((1,0,0),0), ((1,0,1),1), ((1,1,0),1), ((1,1,1),0)]\n",
        "\n",
        "alpha = 0.5 #Learning Rate\n",
        "iterations = 20000 # Number of Iterations\n",
        "epoch = 1000\n",
        "display = True # Displays the Squared Error and Predicted value\n",
        "\n",
        "def BackpropagationBatchVersion(model,learningRate,epoch,data,iterations,display):\n",
        "\n",
        "  w1 = model[0]\n",
        "  w2 = model[1]\n",
        "  v1 = model[2]\n",
        "\n",
        "  avg_deltaV = [0,0,0]\n",
        "  avg_deltaW1 = [0,0,0]\n",
        "  avg_deltaW2 = [0,0,0]\n",
        "\n",
        "  for i in range(iterations):\n",
        "    np.random.shuffle(data) # Shuffling the data\n",
        "\n",
        "    if (i % epoch) == 0:\n",
        "      testData = [ ( (0,0), 0 ), ( (0,1), 1 ), ( (1,0), 1), ( (1,1), 0 ) ]\n",
        "      X = [(1,x1,x2) for ((x1,x2),r) in testData] #Inputs X0,X1,X2\n",
        "      R = [r for ((x1,x2),r) in testData] #Expected Result From Model\n",
        "      yPred = [predict([w1,w2,v1], x) for x in X]  #Predicts the values of Y\n",
        "      squaredError = sum([pow(r - y, 2) for (r,y) in zip(R,yPred)]) #Calculating the Squared Error\n",
        "      if display: print(\"Epoch:\",i, f\"{squaredError=} {yPred=}\")\n",
        "\n",
        "    #Foward Pass Calculations\n",
        "    for (x,r) in data: #1st: x = (1,0,0) r = 0\n",
        "      z1 = sigmoid(F(w1, x))  #Calculating z1 using the sigmoid of w1\n",
        "      z2 = sigmoid(F(w2, x)) #Calculating z2 using the sigmoid of w2\n",
        "      Z = [1, z1, z2] #Hidden Layer (z0 = 1, z1, z2)\n",
        "      y = sigmoid(F(v1,Z)) #Calculating y(output) value\n",
        "\n",
        "      #Backward Pass Calculations\n",
        "      #Similar Calculations to the Logistic regression, but we are applying the z's values (hidden layer)\n",
        "      deltaV = [learningRate * (r - y) * z for z in Z]\n",
        "      deltaZ1 = [learningRate * (r - y) * v1[1] * z1 * (1 - z1) * xLu for xLu in x]\n",
        "      deltaZ2 = [learningRate * (r - y) * v1[2] * z2 * (1 - z2) * xLu for xLu in x]\n",
        "\n",
        "      #Batch Version Implementation\n",
        "      #Adding the delta of all the 4 inputs\n",
        "      avg_deltaV = np.add(avg_deltaV,deltaV)\n",
        "      avg_deltaW1 = np.add(avg_deltaW1,deltaZ1)\n",
        "      avg_deltaW2 = np.add(avg_deltaW2,deltaZ2)\n",
        "\n",
        "    #Divide the deltas by number of inputs to obtain average of delta v, delta w1 and delta w2.\n",
        "    avg_deltaV /= 4\n",
        "    avg_deltaW1 /= 4\n",
        "    avg_deltaW2 /= 4\n",
        "\n",
        "    #Update the edges\n",
        "    #Updates edges from hidden layer nodes to the output node\n",
        "    v1 = [v + dv for (v,dv) in zip(v1,avg_deltaV)]\n",
        "    w1 = [w + dw for (w,dw) in zip(w1,avg_deltaW1)]\n",
        "    w2 = [w + dw for (w,dw) in zip(w2,avg_deltaW2)]\n",
        "\n",
        "  newModel = [w1,w2,v1] #List of final weights [w1,w2,v1]\n",
        "  result = classifyY(yPred) #Classifying the output value to 0 if <0.5 and 1 if >0.5\n",
        "\n",
        "  #Calculating Accuracy\n",
        "  error_rate = sum([math.fabs(r-y) for (r,y) in zip(R,yPred)])/4 *100 #Calculating the Error Rate for Accuracy\n",
        "  accuracy = 100 - error_rate #Calculating Accuracy\n",
        "\n",
        "  #Print Results\n",
        "  print(\"Results:\",result, \"\\tExpected:\",R, \"\\tAccuracy:\",accuracy)\n",
        "\n",
        "  return newModel\n",
        "\n",
        "Final_Weights = BackpropagationBatchVersion(model,alpha,epoch,trainingData,iterations,display)\n",
        "print(f\"{Final_Weights=}\") #Printing the Final Values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c231ea-6438-4d68-d410-dd06d01ef364",
        "id": "_2lwCRQAlP9r"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 squaredError=1.3338459108870355 yPred=[0.2080313520485064, 0.1965160264452184, 0.2256792880250347, 0.21309576884374737]\n",
            "Epoch: 1000 squaredError=0.9861764667388313 yPred=[0.4983997051021526, 0.46500471290901274, 0.5361558812099564, 0.4862127897816332]\n",
            "Epoch: 2000 squaredError=0.012137075011888895 yPred=[0.049310934753091513, 0.9353021782051903, 0.9393465358090195, 0.04290519621567703]\n",
            "Epoch: 3000 squaredError=0.0013685682338526013 yPred=[0.01626585482516117, 0.9785890195338004, 0.9790294202426996, 0.014345553345134607]\n",
            "Epoch: 4000 squaredError=0.00048150876339001555 yPred=[0.00959063266654166, 0.9873215935523116, 0.9874915186643504, 0.008504377288690716]\n",
            "Epoch: 5000 squaredError=0.00024179718786401577 yPred=[0.006773114978912632, 0.9910204297232612, 0.9911133589213856, 0.006026361201540948]\n",
            "Epoch: 6000 squaredError=0.00014463667246638836 yPred=[0.0052262565788821205, 0.9930566017242647, 0.993116457944794, 0.004661435808504243]\n",
            "Epoch: 7000 squaredError=9.601403736761498e-05 yPred=[0.004250720218899489, 0.9943434045111538, 0.9943857901162673, 0.0037985510191672098]\n",
            "Epoch: 8000 squaredError=6.829646467462473e-05 yPred=[0.003580105821634305, 0.9952294796195374, 0.9952614033829895, 0.003204238502573294]\n",
            "Epoch: 9000 squaredError=5.1029702859780755e-05 yPred=[0.003091124510247513, 0.9958764672320402, 0.995901574863625, 0.0027702059553431167]\n",
            "Epoch: 10000 squaredError=3.955741935957363e-05 yPred=[0.0027189647227798624, 0.9963694696121204, 0.9963898587003769, 0.0024394218772672976]\n",
            "Epoch: 11000 squaredError=3.1552705721664963e-05 yPred=[0.002426329036018892, 0.9967575254534546, 0.9967744952768149, 0.0021790161142940054]\n",
            "Epoch: 12000 squaredError=2.5748485554972506e-05 yPred=[0.0021902479809015043, 0.9970708697948795, 0.9970852718325318, 0.0019687191999743117]\n",
            "Epoch: 13000 squaredError=2.1407236879482203e-05 yPred=[0.0019958090239905342, 0.9973291522119841, 0.9973415698860404, 0.0017953564107674256]\n",
            "Epoch: 14000 squaredError=1.8076162448313134e-05 yPred=[0.0018329119301492634, 0.9975456934606178, 0.997556541202178, 0.0016499953996062034]\n",
            "Epoch: 15000 squaredError=1.5464864171177918e-05 yPred=[0.0016944742327127337, 0.9977298419815419, 0.9977394230857953, 0.0015263668733452767]\n",
            "Epoch: 16000 squaredError=1.3380187902385065e-05 yPred=[0.0015753834868532362, 0.9978883509560262, 0.9978968930149673, 0.0014199415820119565]\n",
            "Epoch: 17000 squaredError=1.1689632438819748e-05 yPred=[0.0014718574298369506, 0.998026219916214, 0.9980338973992948, 0.0013273661474527397]\n",
            "Epoch: 18000 squaredError=1.0299863046455361e-05 yPred=[0.0013810381514146697, 0.9981472289405242, 0.998154178079134, 0.0012461049347514655]\n",
            "Epoch: 19000 squaredError=9.14360451205811e-06 yPred=[0.0013007262082053571, 0.9982542888757721, 0.9982606177637604, 0.0011742052420027666]\n",
            "Results: [0, 1, 1, 0] \tExpected: [0, 1, 1, 0] \tAccuracy: 99.85099937973311\n",
            "Final_Weights=[[4.272569758566706, -8.519635407613627, 8.784250997652013], [4.090259237243553, 8.486114629290881, -8.182042318581308], [20.348179843905584, -13.71716194561803, -13.746098695497853]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 times with Batch Version and Initial Random Weights"
      ],
      "metadata": {
        "id": "4s8k53os1hl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display = False\n",
        "\n",
        "model = RandomWeights()\n",
        "print(\"\\n\\n 1st:\")\n",
        "Final_Weights = BackpropagationBatchVersion(model,alpha,epoch,trainingData,iterations,display)\n",
        "print(\"Final Weights:\",Final_Weights)\n",
        "\n",
        "model = RandomWeights()\n",
        "print(\"\\n\\n 2nd:\")\n",
        "Final_Weights = BackpropagationBatchVersion(model,alpha,epoch,trainingData,iterations,display)\n",
        "print(\"Final Weights:\",Final_Weights)\n",
        "\n",
        "model = RandomWeights()\n",
        "print(\"\\n\\n 3rd:\")\n",
        "Final_Weights = BackpropagationBatchVersion(model,alpha,epoch,trainingData,iterations,display)\n",
        "print(\"Final Weights:\",Final_Weights)\n",
        "\n",
        "model = RandomWeights()\n",
        "print(\"\\n\\n 4th:\")\n",
        "Final_Weights = BackpropagationBatchVersion(model,alpha,epoch,trainingData,iterations,display)\n",
        "print(\"Final Weights:\",Final_Weights)\n",
        "\n",
        "model = RandomWeights()\n",
        "print(\"\\n\\n 5th:\")\n",
        "Final_Weights = BackpropagationBatchVersion(model,alpha,epoch,trainingData,iterations,display)\n",
        "print(\"Final Weights:\",Final_Weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "putNn76L1mzF",
        "outputId": "9633d6b5-0df6-49b3-b2ef-90885e200c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " 1st:\n",
            "Results: [0, 1, 1, 0] \tExpected: [0, 1, 1, 0] \tAccuracy: 99.92376511571563\n",
            "Final Weights: [[-3.7083451590490366, 7.999731707065855, 7.998706830899466], [-9.658284008511583, 6.325664875660017, 6.325462225266056], [-7.345650053893183, 15.454633032398412, -16.2011293212306]]\n",
            "\n",
            "\n",
            " 2nd:\n",
            "Results: [0, 1, 1, 0] \tExpected: [0, 1, 1, 0] \tAccuracy: 99.92385705618999\n",
            "Final Weights: [[3.363367868081791, -7.733149548831521, -7.7331780156701475], [9.890904871998016, -6.618215678194476, -6.618220951351781], [-7.468954687694972, -16.025764977123494, 15.58055202836608]]\n",
            "\n",
            "\n",
            " 3rd:\n",
            "Results: [0, 1, 1, 0] \tExpected: [0, 1, 1, 0] \tAccuracy: 99.92311762905162\n",
            "Final Weights: [[3.4233136813859244, -7.8585803288822955, -7.848835689202428], [9.768002428091107, -6.536935945152818, -6.535354552385292], [-7.482232072816154, -15.987484354381005, 15.595543101219185]]\n",
            "\n",
            "\n",
            " 4th:\n",
            "Results: [0, 1, 1, 0] \tExpected: [0, 1, 1, 0] \tAccuracy: 99.92261456241899\n",
            "Final Weights: [[-9.553336550195214, 6.254010600597538, 6.257914364054018], [-3.786455457332289, 8.144294961345377, 8.167510243439986], [-7.3025509163891344, -16.201426079256862, 15.401231065311054]]\n",
            "\n",
            "\n",
            " 5th:\n",
            "Results: [0, 1, 1, 0] \tExpected: [0, 1, 1, 0] \tAccuracy: 99.92500820561565\n",
            "Final Weights: [[-4.0413760381792345, 7.494199040353, -7.779825630675345], [-4.122040820867768, -7.896918391329341, 7.640144137136668], [-7.602604970591114, 15.434423289772871, 15.404712127838295]]\n"
          ]
        }
      ]
    }
  ]
}